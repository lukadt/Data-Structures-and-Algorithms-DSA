% Copyright (C) Data Structures and Algorithms Team.
\chapter{Binary Search Tree} \label{bst}
Binary search tree's (BSTs) are very simple to understand, consider the following where by we have a root node $n$, the left sub tree of $n$ contains values $< n$, the right sub tree however contains nodes whose values are $\geq n$.

BSTs are of interest because they have operations which are favourably fast, insertion, look up, and deletion can all be done in $O(log~n)$. One of the things that I would like to point out and address early is that $O(log~n)$ times for the aforementioned operations can only be attained if the BST is relatively balanced (for a tree data structure with self balancing properties see \S\ref{AVL}). 

\section{Insertion}
As mentioned previously insertion is an $O(log~n)$ operation provided that the tree is moderately balanced.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Insert($value$) \\
2)  \> \textbf{Pre:}~~$value$ has passed custom type checks for type $T$ \\
3)  \> \textbf{Post:}~$value$ has been placed in the correct location in the tree \\
4)  \> \textbf{if}~\= $root~= \emptyset$ \\
5)  \> \> $root \leftarrow$ node($value$) \\
6)  \> \textbf{else} \\
7)  \> \> InsertNode($root$, $value$) \\
8)  \> \textbf{end if} \\
9)  \textbf{end} Insert \\
\end{tabbing}

\newpage
\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} InsertNode($root$, $value$) \\
2)  \> \textbf{Pre:}~~$root$ is the node to start from \\
3)  \> \textbf{Post:}~$value$ has been placed in the correct location in the tree \\
4)  \> \textbf{if}~\= $value < root$.Value \\
5)  \> \> \textbf{if}~\= $root$.Left $= \emptyset$ \\
6)  \> \> \> $root$.Left $\leftarrow$ node($value$) \\
7)  \> \> \textbf{else} \\
8)  \> \> \> InsertNode($root$.Left, $value$) \\
9)  \> \> \textbf{end if} \\
10) \> \textbf{else} \\
11) \> \> \textbf{if} $root$.Right $= \emptyset$ \\
12) \> \> \> $root$.Right $\leftarrow$ node($value$) \\
13) \> \> \textbf{else} \\
14) \> \> \> InsertNode($root$.Right, $value$) \\
15) \> \> \textbf{end if} \\
16) \> \textbf{end if} \\
17) \textbf{end} InsertNode \\ 
\end{tabbing}

The insertion algorithm is split for a good reason, the first algorithm (non-recursive) checks a very core base case - whether or not the tree is empty, if the tree is empty then we simply create our root node and we have no need to invoke the recursive $InsertNode$ algorithm. When the core base case is not met we must invoke the recursive $InsertNode$ algorithm which simply guides us to the first appropriate place in the tree to put $value$.

\section{Searching}
Searching a BST is really quite simple, the pseudo code is self explanatory but I will explain briefly the premise of the algorithm nonetheless.

We have talked previously about insertion, we go either left or right with the right sub tree containing values that are $\geq n$ where $n$ is the value of the node we are inserting, when searching the rules are made a little more atomic and at any one time we have four cases to consider: 
\begin{inparaenum}
\item the $root = \emptyset$ in which case $value$ is not in the BST; or
\item $root$.Value $= value$ in which case $value$ is in the BST; or
\item $value < root$.Value, we must inspect the left sub tree of $root$ for $value$; or
\item $value > root$.Value, we must inspect the right sub tree of $root$ for $value$.
\end{inparaenum}

\newpage
\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Contains($root$, $value$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the tree, $value$ is what we would like to locate \\
3)  \> \textbf{Post:}~$value$ is either located or not \\
4)  \> \textbf{if}~\= $root = \emptyset$ \\
5)  \> \> \textbf{return false} \\
6)  \> \textbf{end if} \\
7)  \> \textbf{if} $root$.Value $= value$ \\
8)  \> \> \textbf{return true} \\
9)  \> \textbf{else if} $value < root$.Value \\
10) \> \> \textbf{return} Contains($root$.Left, $value$) \\
11) \> \textbf{else} \\
12) \> \> \textbf{return} Contains($root$.Right, $value$) \\
13) \> \textbf{end if} \\
14) \textbf{end} Contains \\
\end{tabbing}

\section{Deletion}
Removing a node from a BST is simple, there are four cases that we must consider though: 
\begin{inparaenum}
\item the value to remove is a leaf node; or
\item the value to remove has a right sub tree, but no left sub tree; or
\item the value to remove has a left sub tree, but no right sub tree; or
\item the value to remove has both a left and right sub tree in which case we promote the largest value in the left sub tree.
\end{inparaenum}
The $Remove$ algorithm described later relies on two further helper algorithms named $FindParent$, and $FindNode$ which are described in \S\ref{finding_parent_node} and \S\ref{find_node_reference}.

\newpage
\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Remove($value$) \\
2)  \> \textbf{Pre:}~~$value$ is the value of the node to remove, $root$ is the root node of the BST \\
3)  \> \textbf{Post:}~node with $value$ is removed if found in which case yields true, otherwise false \\
4)  \> $nodeToRemove \leftarrow$ FindNode($value$) \\
5)  \> \textbf{if}~\= $nodeToRemove = \emptyset$ \\
6)  \> \> \textbf{return false} // value not in BST \\
7)  \> \textbf{end if} \\
8)  \> $parent \leftarrow$ FindParent($value$) \\
9)  \> \textbf{if} $count = 1$ // $count$ keeps track of the \# of nodes in the BST \\
10) \> \> $root \leftarrow \emptyset$ // we are removing the only node in the BST \\
11) \> \textbf{else if} $nodeToRemove$.Left $= \emptyset$ \textbf{and} $nodeToRemove$.Right $= null$ \\
12) \> \> // case \#1 \\
13) \> \> \textbf{if}~\= $nodeToRemove$.Value $< parent$.Value \\
14) \> \> \> $parent$.Left $\leftarrow \emptyset$ \\
15) \> \> \textbf{else} \\
16) \> \> \> $parent$.Right $\leftarrow \emptyset$ \\
17) \> \> \textbf{end if} \\
18) \> \textbf{else if} $nodeToRemove$.Left $= \emptyset$ \textbf{and} $nodeToRemove$.Right $!= \emptyset$ \\
19) \> \> // case \# 2 \\
20) \> \> \textbf{if} $nodeToRemove$.Value $< parent$.Value \\
21) \> \> \> $parent$.Left $\leftarrow nodeToRemove$.Right \\
22) \> \> \textbf{else} \\
23) \> \> \> $parent$.Right $\leftarrow nodeToRemove$.Right \\
24) \> \> \textbf{end if} \\
25) \> \textbf{else if} $nodeToRemove$.Left $!= \emptyset$ \textbf{and} $nodeToRemove$.Right $= \emptyset$ \\
26) \> \> // case \#3 \\
27) \> \> \textbf{if} $nodeToRemove$.Value $< parent$.Value \\
28) \> \> \> $parent$.Left $\leftarrow nodeToRemove$.Left \\
29) \> \> \textbf{else} \\
30) \> \> \> $parent$.Right $\leftarrow nodeToRemove$.Left \\
31) \> \> \textbf{end if} \\
32) \> \textbf{else} \\
33) \> \> // case \#4 \\
34) \> \> $largestValue \leftarrow nodeToRemove$.Left \\
35) \> \> \textbf{while} $largestValue$.Right $!= \emptyset$ \\
36) \> \> \> // find the largest value in the left sub tree of $nodeToRemove$ \\
37) \> \> \> $largestValue \leftarrow largestValue$.Right \\
38) \> \> \textbf{end while} \\
39) \> \> // set the parents' Right pointer of $largestValue$ to $\emptyset$ \\
40) \> \> FindParent($largestValue$.Value).Right $\leftarrow \emptyset$ \\
41) \> \> $nodeToRemove$.Value $\leftarrow largestValue$.Value \\
42) \> \textbf{end if} \\
43) \> $count \leftarrow count - 1$ \\
44) \> \textbf{return true} \\
45) \textbf{end} Remove \\
\end{tabbing}

\section{Finding the parent of a given node} \label{finding_parent_node}
The purpose of this algorithm is simple - to return a reference (or a pointer) to the parent node of the node with the given value. We have found that such an algorithm is very useful, especially when performing extensive tree transformations.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} FindParent($value$, $root$) \\
2)  \> \textbf{Pre:}~~$value$ is the value of the node we want to find the parent of \\
3)  \> ~~~~~~~~$root$ is the root node of the BST and is $!= \emptyset$ \\
4)  \> \textbf{Post:}~a reference to the parent node of $value$ if found; otherwise $\emptyset$ \\
5)  \> \textbf{if}~\= $value = root$.Value \\
6)  \> \> \textbf{return} $\emptyset$ \\
7)  \> \textbf{end if} \\
8)  \> \textbf{if} $value < root$.Value \\
9)  \> \> \textbf{if}~\= $root$.Left $= \emptyset$ \\
10) \> \> \> \textbf{return} $\emptyset$ \\
11) \> \> \textbf{else if} $root$.Left.Value $= value$ \\
12) \> \> \> \textbf{return} $root$ \\
13) \> \> \textbf{else} \\
14) \> \> \> \textbf{return} FindParent($value$, $root$.Left) \\
15) \> \> \textbf{end if} \\
16) \> \textbf{else} \\
17) \> \> \textbf{if} $root$.Right $= \emptyset$ \\
18) \> \> \> \textbf{return} $\emptyset$ \\
19) \> \> \textbf{else if} $root$.Right.Value $= value$ \\
20) \> \> \> \textbf{return} $root$ \\
21) \> \> \textbf{else} \\
22) \> \> \> \textbf{return} FindParent($value$, $root$.Right) \\
23) \> \> \textbf{end if} \\
24) \> \textbf{end if} \\
25) \textbf{end} FindParent \\
\end{tabbing}

\section{Attaining a reference to a node} \label{find_node_reference}
Just like the algorithm explained in \S\ref{finding_parent_node} this algorithm we have found to be very useful, it simply finds the node with the specified value and returns a reference to that node.

\newpage
\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} FindNode($value$, $root$) \\
2)  \> \textbf{Pre:}~~$value$ is the value of the node we want to find the parent of \\
3)  \> ~~~~~~~~$root$ is the root node of the BST \\
4)  \> \textbf{Post:}~a reference to the node of $value$ if found; otherwise $\emptyset$ \\
5)  \> \textbf{if}~\= $root = \emptyset$ \\
6)  \> \> \textbf{return} $\emptyset$ \\
7)  \> \textbf{end if} \\
8)  \> \textbf{if} $value < root$.Value \\
9)  \> \> \textbf{return} FindNode($value$, $root$.Left) \\
10) \> \textbf{else if} $value > root$.Value \\
11) \> \> \textbf{return} FindNode($value$, $root$.Right) \\
12) \> \textbf{else} \\
13) \> \> \textbf{return} $root$ \\
14) \> \textbf{end if} \\
15) \textbf{end} FindNode \\
\end{tabbing}

\section{Finding the smallest and largest values in the binary search tree}
A simple task, to find the smallest value in a BST you simply traverse the nodes in the left sub tree of the BST always going left upon each encounter with a node, the opposite is the case when finding the largest value in the BST. Both algorithms are incredibly simple, they are listed simply for completeness.

The base case in both $FindMin$, and $FindMax$ algorithms is when the Left ($FindMin$), or Right ($FindMax$) node references are $\emptyset$.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} FindMin($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> ~~~~~~~~$root$ $!= \emptyset$ \\
4)  \> \textbf{Post:}~the smallest value in the BST is located \\
5)  \> \textbf{if}~\= $root$.Left $= \emptyset$ \\
6)  \> \> \textbf{return} $root$.Value \\
7)  \> \textbf{end if} \\
8)  \> FindMin($root$.Left) \\
9)  \textbf{end} FindMin \\
\end{tabbing}

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} FindMax($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> ~~~~~~~~$root$ $!= \emptyset$ \\
4)  \> \textbf{Post:}~the largest value in the BST is located \\
5)  \> \textbf{if}~\= $root$.Right $= \emptyset$ \\
6)  \> \> \textbf{return} $root$.Value \\
7)  \> \textbf{end if} \\
8)  \> FindMax($root$.Right) \\
9)  \textbf{end} FindMax \\
\end{tabbing}

\section{Tree Traversals}
For the most part when you have a tree you will want to traverse the items in that tree using various strategies in order to attain the node visitation order you require. In this section I will touch on the traversals that DSA provides on all data structures that derive from $BinarySearchTree$.

The algorithms explained in this section will be a lot clearer if you draw out the tree listed in \S\ref{preorder_traversal}, you may also want to draw recursive tree calls which will yield the pragmatic sequence of values.

\subsection{Preorder} \label{preorder_traversal}
When using the preorder algorithm you look at the value of each node that you pass on the left hand side, e.g. given the tree $(23~14(7(~~9)~17)~31)$ using a preorder traversal would yield the following sequence $23, 14, 7, 9, 17, 31$.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Preorder($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> \textbf{Post:}~the nodes in the BST have been visited in preorder \\
4)  \> \textbf{if}~\= $root~!= \emptyset$ \\
5)  \> \> \textbf{yield} $root$.Value \\
6)  \> \> Preorder($root$.Left) \\
7)  \> \> Preorder($root$.Right) \\
8)  \> \textbf{end if} \\
9)  \textbf{end} Preorder \\
\end{tabbing}

\subsection{Postorder} \label{postorder_traversal}
This algorithm is very similar to that described in \S\ref{preorder_traversal}, however the value of the node is yielded after the two recursive calls. When you traverse the nodes in a postorder fashion the value of the node is yielded upon passing the node on the right hand side, e.g. given the same tree as listed in \S\ref{preorder_traversal} the following sequence is yielded $9, 7, 17, 14, 31, 23$.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Postorder($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> \textbf{Post:}~the nodes in the BST have been visited in postorder \\
4)  \> \textbf{if}~\= $root~!= \emptyset$ \\
5)  \> \> Postorder($root$.Left) \\
6)  \> \> Postorder($root$.Right) \\
7)  \> \> \textbf{yield} $root$.Value \\
8)  \> \textbf{end if} \\
9)  \textbf{end} Postorder \\
\end{tabbing}

\subsection{Inorder}
Another variation of the algorithms defined in \S\ref{preorder_traversal} and \S\ref{postorder_traversal} is that of inorder traversal where the value of the current node is yielded in between the recursive calls. Inorder traversal yields the value of each node when passing underneath that node, e.g. given the tree listed in \S\ref{preorder_traversal} the following sequence is yielded $7, 9, 14, 17, 23, 31$ - the sequence is that of the values in the BST in ascending order.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} Inorder($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> \textbf{Post:}~the nodes in the BST have been visited in inorder \\
4)  \> \textbf{if}~\= $root~!= \emptyset$ \\
5)  \> \> Inorder($root$.Left) \\
6)  \> \> \textbf{yield} $root$.Value \\
7)  \> \> Inorder($root$.Right) \\
8)  \> \textbf{end if} \\
9)  \textbf{end} Inorder \\
\end{tabbing}

\subsection{Breadth First}
Traversing a tree in breadth first order is to yield the values of all nodes of a particular depth in the tree, e.g. given the depth $d$ we would visit the values of all nodes in a left to right fashion at $d$, then we would proceed to $d+1$ and so on until we had ran out of nodes to visit. Consider the tree listed in \S\ref{preorder_traversal} if we were to traverse the nodes in breadth first order then the following sequence would be yielded $23, 14, 31, 7, 17, 9$. 

Traditionally the way breadth first is implemented is using a list (vector, resizeable array, etc) to store the values of the nodes visited in breadth first order and then a queue to store those nodes that have yet to be visited.

\begin{tabbing}
1)  \textbf{alg}\= \textbf{orithm} BreadthFirst($root$) \\
2)  \> \textbf{Pre:}~~$root$ is the root node of the BST \\
3)  \> \textbf{Post:}~the nodes in the BST have been visited in breadth first order \\
4)  \> $l \leftarrow$ list \\
5)  \> $q \leftarrow$ queue \\
6)  \> \textbf{whi}\= \textbf{le} $root~!= \emptyset$ \\
7)  \> \> $l$.Add($root$.Value) \\
8)  \> \> \textbf{if}~\= $root$.Left $!= \emptyset$ \\
9)  \> \> \> $q$.Enqueue($root$.Left) \\
10) \> \> \textbf{end if} \\
11) \> \> \textbf{if} $root$.Right $!= \emptyset$ \\
12) \> \> \> $q$.Enqueue($root$.Right) \\
13) \> \> \textbf{end if} \\
14) \> \> \textbf{if} $!q$.IsEmpty() \\
15) \> \> \> $root \leftarrow q$.Dequeue() \\
16) \> \> \textbf{else} \\
17) \> \> \> $root \leftarrow \emptyset$ \\
18) \> \> \textbf{end if} \\
19) \> \textbf{end while} \\
20) \> \textbf{return} $l$ \\
21) \textbf{end} BreadthFirst \\
\end{tabbing}
